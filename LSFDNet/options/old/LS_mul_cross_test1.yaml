# general settings
name: train_MulFMtestLS1
model_type: MulFM
phase: train
num_gpu: 2
manual_seed: 0


# dataset and data loader settings
datasets:
  train:
    name: train
    type: OSLSP_FusionDataset
    crop_size: 320
    LW_path: '/data/gyy/OSLSP/LWIR/'
    SW_path: '/data/gyy/OSLSP/SWIR/'
    paired_path: '/data/gyy/OSLSP/gama/'
    label_path: '/data/gyy/OSLSP/labels/'
    is_crop: True
    is_size: False
    is_pad: False
    batch_size_per_gpu: 8
    num_worker_per_gpu: 6
    pin_memory: True
    data_len: -1

  val:
    # Please modify accordingly to use your own validation
    # Or comment the val block if do not need validation during training
    name: val
    type: OSLSP_FusionDataset
    crop_size: 320
    LW_path: '/data/gyy/OSLSP_test/LWIR/'
    SW_path: '/data/gyy/OSLSP_test/SWIR/'
    paired_path: '/data/gyy/OSLSP_test/gama/'
    label_path: '/data/gyy/OSLSP_test/labels/'
    is_crop: True
    is_size: False
    is_pad: False
    batch_size_per_gpu: 8
    num_worker_per_gpu: 1
    pin_memory: True
    data_len: -1


# network structures
network_ft_extra:
  type: FeatureExtractorMulNet

network_fusion_head:
  type: crossFusion
      
# path
path:
  pretrain_network_C2FM: ~
  pretrain_network_TRFM: ~
  training_states:
  strict_load_g: true
  resume_state: ~

# training settings
train:
  a: 0.9 #大就是全局
  b: 0.1  #大就是强度
  c: 0.1   #大就是强度
  #n_epoch: 300
  optimizer:
      type: Adam
      lr: !!float 1e-4

  scheduler:
    type: MultiStepLR
    milestones: [50000, 75000, 100000, 150000, 200000]
    gamma: 0.5

  total_iter: 300000
  warmup_iter: -1  # no warm up

  #Loss
  Loss_LS:
    type: Fusionloss_LS

val:
  pbar: true
  start_val: 0
  val_freq: !!float 100
  save_img: true
 
  metrics:
    EN: 
      type: ~
    SF: 
      type: ~
    AG: 
      type: ~
    SD: 
      type: ~
    CC: 
      type: ~
    SCD: 
      type: ~
    MSE: 
      type: ~
    PSNR: 
      type: ~
    Qabf: 
      type: ~
    Nabf: 
      type: ~


# logging settings
logger:
  print_freq: 50
  start_save: 0
  save_checkpoint_freq: !!float 10000
  use_tb_logger: true
  wandb:
    project: ~
    resume_id: ~

# dist training settings
dist_params:
  backend: nccl
  port: 29500

find_unused_parameters: true
